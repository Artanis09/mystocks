# -*- coding: utf-8 -*-
"""
Inference - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë° ì¶”ì²œ ì¢…ëª© ìƒì„±
"""
import os
import glob
import json
from datetime import datetime
from typing import List, Dict, Tuple, Optional

import numpy as np
import pandas as pd
from catboost import CatBoostClassifier

from ml.config import CFG
from ml.data_pipeline import load_all_bars, compute_technical_indicators, get_feature_columns


def load_model(model_path: str = None) -> Tuple[CatBoostClassifier, dict]:
    """
    í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    """
    if model_path is None:
        # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ë¡œë“œ
        model_files = glob.glob(os.path.join(CFG.model_dir, 'catboost_*.cbm'))
        if not model_files:
            raise FileNotFoundError("No trained model found. Run train.py first.")
        model_path = max(model_files, key=os.path.getctime)
    
    model = CatBoostClassifier()
    model.load_model(model_path)
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    meta_path = model_path.replace('.cbm', '_meta.json')
    meta = {}
    if os.path.exists(meta_path):
        with open(meta_path, 'r', encoding='utf-8') as f:
            meta = json.load(f)
    
    print(f"[INFO] Model loaded: {model_path}")
    return model, meta


def get_recent_data(lookback_days: int = 300) -> pd.DataFrame:
    """
    ìµœê·¼ Nì¼ê°„ì˜ ë°ì´í„° ë¡œë“œ (í”¼ì²˜ ê³„ì‚°ì„ ìœ„í•œ ì¶©ë¶„í•œ ê¸°ê°„)
    """
    bars_dir = CFG.bars_dir
    partitions = sorted([
        d for d in os.listdir(bars_dir) 
        if d.startswith('date=')
    ], reverse=True)
    
    # ìµœê·¼ Nê°œ íŒŒí‹°ì…˜ë§Œ ë¡œë“œ
    recent_partitions = partitions[:lookback_days]
    
    all_data = []
    for partition in recent_partitions:
        path = os.path.join(bars_dir, partition, 'part-0000.parquet')
        if os.path.exists(path):
            df = pd.read_parquet(path)
            all_data.append(df)
    
    if not all_data:
        raise ValueError("No recent data found")
    
    result = pd.concat(all_data, ignore_index=True)
    result['date'] = pd.to_datetime(result['date'])
    result = result.sort_values(['code', 'date']).reset_index(drop=True)
    
    return result


def prepare_inference_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì¶”ë¡ ì„ ìœ„í•œ í”¼ì²˜ ì¤€ë¹„ (ìµœì‹  ë‚ ì§œë§Œ)
    """
    # ì¢…ëª©ë³„ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    results = []
    for code, group in df.groupby('code'):
        group = group.sort_values('date').reset_index(drop=True)
        if len(group) < 60:
            continue
        
        processed = compute_technical_indicators(group)
        # ë§ˆì§€ë§‰ í–‰ë§Œ (ê°€ì¥ ìµœê·¼ ë‚ ì§œ)
        # 0.8 í™•ë¥  ì „ëµì— í•„ìš”í•œ open ê°€ê²© ìœ ì§€ë¥¼ ìœ„í•´ select ì‹œ í¬í•¨ í™•ì¸
        results.append(processed.iloc[-1:])
    
    if not results:
        raise ValueError("No valid data for inference")
    
    return pd.concat(results, ignore_index=True)


def predict_next_day(
    model: CatBoostClassifier,
    df: pd.DataFrame,
    top_k: int = 5,
    min_prob_threshold: float = 0.8
) -> pd.DataFrame:
    """
    ë‹¤ìŒ ë‚  ìƒìŠ¹ ì˜ˆì¸¡ - ìµœì¢… í•„í„° ì¡°ê±´ ì ìš©
    1. í™•ë¥  >= 80% (ê¸°ë³¸ê°’)
    2. ì‹œê°€ì´ì•¡ >= 500ì–µ
    3. ë‹¹ì¼ ì‹œê°€ ëŒ€ë¹„ ì¢…ê°€ ë³€ë™ë¥  > -5%
    """
    feature_cols = get_feature_columns()
    
    # 1. ì‹œê°€ì´ì•¡ í•„í„° ì¤€ë¹„ (ìƒì¥ì£¼ì‹ìˆ˜ ë¡œë“œ)
    try:
        stocks_info = pd.read_csv('public/korea_stocks.csv')
        stocks_info['ë‹¨ì¶•ì½”ë“œ'] = stocks_info['ë‹¨ì¶•ì½”ë“œ'].apply(lambda x: str(x).zfill(6))
        code_to_shares = dict(zip(stocks_info['ë‹¨ì¶•ì½”ë“œ'], stocks_info['ìƒì¥ì£¼ì‹ìˆ˜']))
        
        df = df.copy()
        df['shares'] = df['code'].map(code_to_shares).fillna(0)
        df['market_cap'] = df['close'] * df['shares']
    except Exception as e:
        print(f"[WARN] Failed to load market cap info: {e}")
        df['market_cap'] = 1e12  # ì •ë³´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤ (1ì¡° ê°€ì •)
    
    # 2. í”¼ì²˜ ì¶”ì¶œ ë° ì˜ˆì¸¡
    X = df[feature_cols].values
    proba = model.predict_proba(X)
    
    # 2% ì´ìƒ ìƒìŠ¹ í™•ë¥  (í´ë˜ìŠ¤ 1 ì´ìƒì˜ í•©)
    positive_proba = proba[:, CFG.min_positive_class:].sum(axis=1)
    
    # ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê¸°ëŒ€ ìˆ˜ìµë¥ 
    class_returns = np.array([0.0, 0.035, 0.065, 0.10, 0.155, 0.24, 0.35])
    expected_return = (proba * class_returns).sum(axis=1)
    
    # ê²°ê³¼ DataFrame ìƒì„±
    result = df[['date', 'code', 'close', 'open', 'market_cap']].copy()
    result['positive_proba'] = positive_proba
    result['expected_return'] = expected_return
    
    # 3. ìµœì¢… í•„í„° ì ìš©
    # 3.1 í™•ë¥  ì„ê³„ê°’ (ê¸°ë³¸ 80%)
    mask = (result['positive_proba'] >= min_prob_threshold)
    # 3.2 ì‹œê°€ì´ì•¡ 500ì–µ ì´ìƒ
    mask &= (result['market_cap'] >= 50_000_000_000)
    # 3.3 ë‹¹ì¼ ì‹œê°€ ëŒ€ë¹„ ì¢…ê°€ ë³€ë™ë¥  -5% ì´ìƒ (ì¥ëŒ€ìŒë´‰ ì œì™¸)
    day_change = (result['close'] - result['open']) / result['open']
    mask &= (day_change > -0.05)
    
    candidates = result[mask].copy()
    
    # ê¸°ëŒ€ ìˆ˜ìµë¥  ìˆœìœ¼ë¡œ ì •ë ¬
    candidates = candidates.sort_values('expected_return', ascending=False)
    
    # ìƒìœ„ Kê°œ ì„ íƒ
    top_candidates = candidates.head(top_k)
    
    return top_candidates


def get_stock_name_mapping() -> Dict[str, str]:
    """
    ì¢…ëª©ì½”ë“œ-ì¢…ëª©ëª… ë§¤í•‘ ë¡œë“œ
    """
    # 1. korea_stocks.csv (ìµœì‹  ìƒì¥ì£¼ì‹ìˆ˜ í¬í•¨)
    csv_path = 'public/korea_stocks.csv'
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            df['ë‹¨ì¶•ì½”ë“œ'] = df['ë‹¨ì¶•ì½”ë“œ'].apply(lambda x: str(x).zfill(6))
            return dict(zip(df['ë‹¨ì¶•ì½”ë“œ'], df['í•œê¸€ ì¢…ëª©ì•½ëª…']))
        except:
            pass

    # 2. tickers.parquet (ë°±ì—…)
    tickers_path = os.path.join('data/krx/master/tickers.parquet')
    if os.path.exists(tickers_path):
        df = pd.read_parquet(tickers_path)
        return dict(zip(df['code'], df['name']))
    
    return {}


def run_inference(
    model_path: str = None,
    top_k: int = 5,
    min_prob_threshold: float = 0.8,
    save_result: bool = True
) -> pd.DataFrame:
    """
    ì „ì²´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    print("=" * 60)
    print("Stock Price Prediction - Inference (Final Strategic Filter)")
    print(f"Condition: Top-{top_k}, Prob >= {min_prob_threshold*100}%, Cap >= 50B, Daily > -5%")
    print("=" * 60)
    
    # ëª¨ë¸ ë¡œë“œ
    model, meta = load_model(model_path)
    
    # ìµœê·¼ ë°ì´í„° ë¡œë“œ
    print("\n[INFO] Loading recent data...")
    recent_data = get_recent_data(lookback_days=300)
    latest_date = recent_data['date'].max().strftime('%Y-%m-%d')
    print(f"[INFO] Latest data date: {latest_date}")
    
    # í”¼ì²˜ ì¤€ë¹„
    print("[INFO] Preparing features...")
    inference_data = prepare_inference_features(recent_data)
    print(f"[INFO] {len(inference_data)} stocks ready for prediction")
    
    # ì˜ˆì¸¡
    print(f"[INFO] Running Filtered Prediction...")
    predictions = predict_next_day(
        model, 
        inference_data, 
        top_k=top_k,
        min_prob_threshold=min_prob_threshold
    )
    
    # ì¢…ëª©ëª… ì¶”ê°€
    name_mapping = get_stock_name_mapping()
    predictions['name'] = predictions['code'].map(name_mapping).fillna('Unknown')
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print(f"ğŸš€ FINAL TOP-{len(predictions)} STRATEGIC PICKS for {latest_date} â†’ Next Day")
    print("=" * 60)
    
    if len(predictions) == 0:
        print("  [WARN] No stocks met the strict filter criteria today.")
    else:
        for i, (idx, row) in enumerate(predictions.iterrows()):
            prob_str = f"{row['positive_proba']*100:.1f}%"
            cap_str = f"{row['market_cap']/1e8:,.0f}ì–µ"
            exp_ret = f"{row['expected_return']*100:.2f}%"
            print(f"  {i+1}. {row['code']} {row['name'][:8]:<8} | "
                  f"ì¢…ê°€: {row['close']:>8,.0f} | "
                  f"ì‹œì´: {cap_str:>7} | "
                  f"ìƒìŠ¹í™•ë¥ : {prob_str:>6} | "
                  f"ê¸°ëŒ€ìˆ˜ìµ: {exp_ret:>6}")
    
    # ê²°ê³¼ ì €ì¥
    if save_result:
        os.makedirs('ml/predictions', exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = f'ml/predictions/final_picks_{timestamp}.csv'
        predictions.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\n[INFO] Strategic picks saved to {output_path}")
    
    return predictions


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ìµœì¢… ì „ëµ ì¡°ê±´ ê¸°ë³¸ê°’ ì„¤ì •)
    """
    predictions = run_inference(
        top_k=5,            # ìµœì¢… ì „ëµ: ìƒìœ„ 5ê°œ
        min_prob_threshold=0.8,  # ìµœì¢… ì „ëµ: 80% ì´ìƒ
        save_result=True
    )
    
    print("\n[SUCCESS] Strategic inference completed!")
    
    return predictions


if __name__ == "__main__":
    main()
